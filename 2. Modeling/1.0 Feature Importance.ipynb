{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import sort\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moudule Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    features=\\\n",
    "    [\n",
    "     'stay_duration', #f1\n",
    "     'mfcc0','mfcc1','mfcc2','mfcc3','mfcc4', #f2,f3,f4,f5,f6\n",
    "     'wifi_count', 'edge_wifi_count', #f7,f8\n",
    "     'RSI', #f9\n",
    "     'human_made', 'natural_land','road_exist_percent','highly_populated_poi_exist'#f10,f11,f12,f13\n",
    "     ]\n",
    "\n",
    "    labels=['Is_Bus_stop','Is_Turn', 'Is_Signal','Is_Congestion', 'Is_Adhoc']\n",
    "\n",
    "####FEATURES ARE NAMED IN THIS FASHION##############################################\n",
    "    feature_namming=\\\n",
    "    {\n",
    "     'stay_duration':\"$\\mathbf{f_{1}}$\", #f1\n",
    "     'mfcc0':\"$\\mathbf{f_{2}}$\",'mfcc1':\"$\\mathbf{f_{3}}$\",'mfcc2':\"$\\mathbf{f_{4}}$\",'mfcc3':\"$\\mathbf{f_{5}}$\",'mfcc4':\"$\\mathbf{f_{6}}$\", #f2,f3,f4,f5,f6\n",
    "     'wifi_count':\"$\\mathbf{f_{7}}$\", 'edge_wifi_count':\"$\\mathbf{f_{8}}$\", #f7,f8\n",
    "     'RSI':\"$\\mathbf{f_{9}}$\", #f9\n",
    "     'human_made':\"$\\mathbf{f_{10}}$\", 'natural_land':\"$\\mathbf{f_{11}}$\",'road_exist_percent':\"$\\mathbf{f_{12}}$\",'highly_populated_poi_exist':\"$\\mathbf{f_{13}}$\"#f10,f11,f12,f13\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDict:\n",
    "    def __init__(self,d):\n",
    "        self.dic=d\n",
    "    def normalize(self):\n",
    "        a=np.array(list(self.dic.values()))\n",
    "        return myDict(dict(zip(self.dic.keys(),(a-a.min())/a.max())))\n",
    "    def __repr__(self):\n",
    "        return str(self.dic)\n",
    "    def __add__(self,other):\n",
    "        return myDict(dict(pd.Series(self.dic)+pd.Series(other.dic)))\n",
    "    def __truediv__(self,val):\n",
    "        return myDict(dict(zip(self.dic.keys(),np.array(list(self.dic.values()))/val)))\n",
    "    def keys(self):\n",
    "        return self.dic.keys()\n",
    "    def values(self):\n",
    "        return self.dic.values()\n",
    "    def get_sorted(self):\n",
    "        a=list(zip(self.dic.keys(),self.dic.values()))\n",
    "        return myDict(dict(sorted(a,key=lambda e:e[1])))\n",
    "    \n",
    "def get_feature_set_for(target_column):\n",
    "    df=pd.read_csv('./Datasets/DataSet_54F_mfcc.csv')\n",
    "\n",
    "    Labels=df[target_column].values\n",
    "    Features=df[features]\n",
    "\n",
    "    return Features,Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_feature_f1_score(target_class,importance_dict,checkfor=30):\n",
    "    f1_mean_l=[]\n",
    "    f1_std_l=[]\n",
    "    fsize=len(importance_dict.keys())\n",
    "    for feat in range(1,fsize+1):\n",
    "        f1_l=[]\n",
    "        taken_feat=list(importance_dict.keys())[-feat:]\n",
    "        for _ in range(checkfor):\n",
    "            X,y=get_feature_set_for(target_class)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X[taken_feat], y, test_size=0.33, random_state=None,stratify=y)\n",
    "\n",
    "            model = RandomForestClassifier()#n_estimators=20,max_depth=8)#XGBClassifier()\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            f1=f1_score(y_test,model.predict(X_test),average='weighted') #f1 score is calculated\n",
    "            f1_l.append(f1)\n",
    "        f1_mean_l.append(np.mean(f1_l))\n",
    "        f1_std_l.append(np.std(f1_l))\n",
    "\n",
    "    return f1_mean_l,f1_std_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_columns=features[:] #copy of features array\n",
    "num_feat=len(feat_columns)\n",
    "    \n",
    "def Feature_Importance(target_class,run_cases=100,eachcheckfor=30):\n",
    "    \n",
    "    Sum=myDict(dict(zip(feat_columns,[0]*num_feat))) #zero_initilization\n",
    "\n",
    "    for _ in range(run_cases):\n",
    "        X,y=get_feature_set_for(target_class)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=None,stratify=y)\n",
    "        \n",
    "        print('{}: on run {}'.format(target_class,_))\n",
    "        model = RandomForestClassifier()#n_estimators=20,max_depth=8)#XGBClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        Sum+=myDict(dict(zip(X.columns,model.feature_importances_)))\n",
    "\n",
    "    avg=Sum/run_cases\n",
    "    avg=avg.get_sorted()\n",
    "    \n",
    "    print('checking feature adding F1-Score')\n",
    "    f1_mean_l_c,f1_std_l_c=check_feature_f1_score(target_class,avg,eachcheckfor)\n",
    "    \n",
    "    return avg,f1_mean_l_c,f1_std_l_c #returninig (AVG_importance, f1_mean_list, f1_std_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY RUN IF NECESSARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "bus_stop_fi,bus_stop_f1,bus_stop_f1_std=Feature_Importance('Is_Bus_stop',100,30)\n",
    "norm_road_fi,norm_road_f1,norm_road_f1_std=Feature_Importance('Is_Adhoc',100,30)\n",
    "Signal_fi,Signal_f1,Signal_f1_std=Feature_Importance('Is_Signal',100,30)\n",
    "Turn_fi,Turn_f1,Turn_f1_std=Feature_Importance('Is_Turn',100,30)\n",
    "Congestion_fi,Congestion_f1,Congestion_f1_std=Feature_Importance('Is_Congestion',100,30)\n",
    "clear_output()\n",
    "\n",
    "#SAVE IMPORTANCES FOR FUTURE ACCESS\n",
    "importance={\n",
    "    'bus':{'imp':bus_stop_fi,'f1_mean':bus_stop_f1,\"f1_std\":bus_stop_f1_std},\n",
    "    'turn':{'imp':Turn_fi,'f1_mean':Turn_f1,\"f1_std\":Turn_f1_std},\n",
    "    'signal':{'imp':Signal_fi,'f1_mean':Signal_f1,\"f1_std\":Signal_f1_std},\n",
    "    'congestion':{'imp':Congestion_fi,'f1_mean':Congestion_f1,\"f1_std\":Congestion_f1_std},\n",
    "    'adhoc':{'imp':norm_road_fi,'f1_mean':norm_road_f1,\"f1_std\":norm_road_f1_std}\n",
    "}\n",
    "\n",
    "import pickle\n",
    "with open('./logs/importance.pickle', 'wb') as handle:\n",
    "    pickle.dump(importance, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Importance PICKLE IS SAVED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY LOAD IMPORTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD PREVIOUS CALCULATED IMPORTANCES\n",
    "import pickle\n",
    "with open('./logs/importance.pickle', 'rb') as handle:\n",
    "    IMPORTANCE = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DRAW CHARTS.....\n",
    "#Importance\n",
    "def get_importance_chart(target_fi):\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "    feats=list(map(lambda name:feature_namming[name],list(target_fi.keys())))\n",
    "    importances=list(target_fi.values())\n",
    "\n",
    "    ax.barh(feats,importances,color=sns.color_palette('hot_r',num_feat),ec='k',linewidth=3)\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel('Importance',fontsize=22, fontweight='bold')\n",
    "    ax.set_ylabel('Features',fontsize=22, fontweight='bold')\n",
    "    plt.yticks(fontsize=22, fontweight='bold')\n",
    "    ax.grid()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING ALL FEATURE IMPORTANCES\n",
    "get_importance_chart(IMPORTANCE[\"bus\"][\"imp\"]).savefig(\"./logs/Figures/bus.png\")\n",
    "get_importance_chart(IMPORTANCE[\"turn\"][\"imp\"]).savefig(\"./logs/Figures/turn.png\")\n",
    "get_importance_chart(IMPORTANCE[\"signal\"][\"imp\"]).savefig(\"./logs/Figures/signal.png\")\n",
    "get_importance_chart(IMPORTANCE[\"congestion\"][\"imp\"]).savefig(\"./logs/Figures/congestion.png\")\n",
    "get_importance_chart(IMPORTANCE[\"adhoc\"][\"imp\"]).savefig(\"./logs/Figures/adhoc.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Incremental feat performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score_line_plots(linewidth=5):\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "    ax.errorbar(list(map(str,range(1,num_feat+1))),IMPORTANCE[\"bus\"][\"f1_mean\"],yerr=IMPORTANCE[\"bus\"][\"f1_std\"],label='Bus Stop',capsize=linewidth,linewidth=linewidth,linestyle='solid',markeredgewidth=linewidth)\n",
    "\n",
    "    ax.errorbar(list(map(str,range(1,num_feat+1))),IMPORTANCE[\"turn\"][\"f1_mean\"],yerr=IMPORTANCE[\"turn\"][\"f1_std\"],label='Turn',capsize=linewidth,linewidth=linewidth,linestyle='dotted',markeredgewidth=linewidth)\n",
    "\n",
    "    ax.errorbar(list(map(str,range(1,num_feat+1))),IMPORTANCE[\"signal\"][\"f1_mean\"],yerr=IMPORTANCE[\"signal\"][\"f1_std\"],label='Signal',capsize=linewidth,linewidth=linewidth,linestyle='dashed',markeredgewidth=linewidth)\n",
    "\n",
    "    ax.errorbar(list(map(str,range(1,num_feat+1))),IMPORTANCE[\"congestion\"][\"f1_mean\"],yerr=IMPORTANCE[\"congestion\"][\"f1_std\"],label='Congestion',capsize=linewidth,linewidth=linewidth,linestyle='dashdot',markeredgewidth=linewidth)\n",
    "\n",
    "    ax.errorbar(list(map(str,range(1,num_feat+1))),IMPORTANCE[\"adhoc\"][\"f1_mean\"],yerr=IMPORTANCE[\"adhoc\"][\"f1_std\"],label='Adhoc',capsize=linewidth,linewidth=linewidth,linestyle=':',marker='o',markeredgewidth=linewidth)\n",
    "\n",
    "    plt.xlabel(\"# Top Features\",fontsize=22, fontweight='bold')\n",
    "    plt.ylabel(\"F1-score(Weighted)\",fontsize=22, fontweight='bold')\n",
    "\n",
    "    plt.yticks(fontsize=22, fontweight='bold')\n",
    "    plt.xticks(fontsize=22, fontweight='bold')\n",
    "    plt.ylim(0.4,1)\n",
    "\n",
    "    ax.legend(loc=\"best\",prop={'size':22,'weight':'bold'})\n",
    "    plt.grid()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_f1_score_line_plots(linewidth=4).savefig(\"./logs/Figures/overall_f1_progress_lw4.png\")\n",
    "get_f1_score_line_plots(linewidth=5).savefig(\"./logs/Figures/overall_f1_progress_lw5.png\")\n",
    "get_f1_score_line_plots(linewidth=7).savefig(\"./logs/Figures/overall_f1_progress_lw7.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

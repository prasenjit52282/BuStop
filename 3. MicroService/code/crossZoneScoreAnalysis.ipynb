{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import itertools\n",
    "from library.correlationAndTtestLib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_zone_cal(s):\n",
    "    '''\n",
    "    @param s: a string of format \"hh:mm:ss\"\n",
    "    \n",
    "    @return: a string denoting the timezone\n",
    "    '''\n",
    "    hour=int(s.split(':')[0])\n",
    "\n",
    "    if 6<hour<=9:\n",
    "        time_zone='Early_Morning'\n",
    "    elif 9<hour<=12:\n",
    "        time_zone='Morning'\n",
    "    elif 12<hour<=17:\n",
    "        time_zone='Afternoon'\n",
    "    elif 17<hour<=23:\n",
    "        time_zone='Evening'\n",
    "    return time_zone\n",
    "\n",
    "# converts hour:minute:seconds to seconds\n",
    "def time_as_int(timestr):\n",
    "    '''\n",
    "    @param timestr: a string of format \"hh:mm:ss\"\n",
    "    \n",
    "    @return: an integer denoting the time in seconds\n",
    "    '''\n",
    "    hh, mm, ss = timestr.split(\":\")\n",
    "    time_int = (int(hh)*3600)+(int(mm)*60)+int(ss)\n",
    "    return time_int\n",
    "\n",
    "def get_day_of_week(date_string, seperator=\"/\", date_format=\"mm/dd/yyyy\"):\n",
    "    '''\n",
    "    @param date_string: a string denoting a date\n",
    "    @param seperator (optional): a character which acts as seperator in the date_string. Default = \"/\"\n",
    "    @param date_format (optional): a string which denotes the format the date string is. Default = \"mm/dd/yyyy\"\n",
    "                                Supported values are : {\"dd/mm/yyyy\", \"mm/dd/yyyy\"}\n",
    "    \n",
    "    @return: a string denoting the day of week corressponding to the date denoted by date_string\n",
    "    '''\n",
    "    date_format_idxs = {'mm/dd/yyyy':{'date_idx': 1, 'month_idx': 0, 'year_idx': 2},\n",
    "                        'dd/mm/yyyy':{'date_idx': 0, 'month_idx': 1, 'year_idx': 2}}\n",
    "    try:\n",
    "        idx_dict = date_format_idxs[date_format]\n",
    "        date_arr = [int(val) for val in date_string.split(seperator)]\n",
    "        weekdays = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\", 4:\"Friday\", 5:\"Saturday\", 6:\"Sunday\"}\n",
    "        date = datetime.datetime(date_arr[idx_dict['year_idx']],\\\n",
    "                                 date_arr[idx_dict['month_idx']],\\\n",
    "                                 date_arr[idx_dict['date_idx']])\n",
    "        return weekdays[date.weekday()]\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"{date_format} is not supported. Supported values are: {list(date_format_idxs.keys())}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = [\"junct_mall\", \"prantika_bus_stand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = r\"../reports/54ft/\"\n",
    "instance_wise_scores_dir = \"instance_wise_scores\"\n",
    "\n",
    "dates = [\"14_09_2019\", \"15_09_2019\", \"16_09_2019\", \"17_09_2019\", \"20_09_2019\", \"21_09_2019\", \"23_09_2019\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_timezone_analysis_dfs = []\n",
    "for zone in zones:\n",
    "    path = os.path.join(log_dir, zone, f\"time_zone_analysis/score_timezone_analysis_{zone}_zone.csv\")\n",
    "    zone_timezone_analysis_dfs.append(pd.read_csv(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Welch's (t_test_stat, p_value) for zones ['junct_mall', 'prantika_bus_stand']: (6.9628689398734664, 2.0936879865449384e-05)\n"
     ]
    }
   ],
   "source": [
    "array_1, array_2 = zone_timezone_analysis_dfs[0]['Whole_Day'], zone_timezone_analysis_dfs[1]['Whole_Day']\n",
    "zonal_welch_t_result = welch_t_test(array_1, array_2)\n",
    "print(f\"Welch's (t_test_stat, p_value) for zones {zones}: {zonal_welch_t_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dfs = {}\n",
    "\n",
    "for zone in zones:\n",
    "    for date in dates:\n",
    "        score_dfs[zone] = score_dfs.get(zone, {})\n",
    "        score_dfs[zone][date] = pd.read_csv(os.path.join(log_dir, zone, \n",
    "                                                      instance_wise_scores_dir, \n",
    "                                                      f\"{date}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "for zone in score_dfs.keys():\n",
    "    for date in dates:\n",
    "        temp_df = score_dfs.get(zone).get(date)\n",
    "        temp_df['Date'] = [date for i in range(len(temp_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "53\n54\n"
     ]
    }
   ],
   "source": [
    "joined_dfs = {}\n",
    "for zone in score_dfs.keys():\n",
    "    temp_df = pd.concat(score_dfs[zone].values(), ignore_index=True)\n",
    "    joined_dfs[zone] = temp_df\n",
    "    print(len(temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_df in joined_dfs.values():\n",
    "    temp_df['Timezone'] = temp_df['start_time'].apply(lambda x : time_zone_cal(x))\n",
    "    temp_df['Day'] = temp_df['Date'].apply(lambda x : get_day_of_week(x, seperator=\"_\", date_format=\"dd/mm/yyyy\"))\n",
    "#     print(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For junct_mall: \n\tFor 14_09_2019:\n\t\tAfternoon, Morning: 2,3\n\t\tAfternoon, Morning:(1.0, 0.42264973081037427)\n\n\tFor 15_09_2019:\n\t\tOnly 1 timezone available:\t[('15_09_2019', 'Afternoon')].\n\n\tFor 16_09_2019:\n\t\tAfternoon, Evening: 7,2\n\t\tAfternoon, Evening:(0.6868028197434451, 0.6029039678713222)\n\n\tFor 17_09_2019:\n\t\tAfternoon, Evening: 3,2\n\t\tAfternoon, Evening:(-1.8410785575880018, 0.1660703195925413)\n\n\tFor 20_09_2019:\n\t\tAfternoon, Evening: 6,1\n\t\tAfternoon, Evening:(nan, nan)\n\n\tFor 21_09_2019:\n\t\tAfternoon, Evening: 4,1\n\t\tAfternoon, Evening:(nan, nan)\n\n\tFor 23_09_2019:\n\t\tAfternoon, Evening: 4,1\n\t\tAfternoon, Evening:(nan, nan)\n\nFor prantika_bus_stand: \n\tFor 14_09_2019:\n\t\tOnly 1 timezone available:\t[('14_09_2019', 'Morning')].\n\n\tFor 15_09_2019:\n\t\tOnly 1 timezone available:\t[('15_09_2019', 'Afternoon')].\n\n\tFor 16_09_2019:\n\t\tAfternoon, Evening: 8,2\n\t\tAfternoon, Evening:(1.7621447994377786, 0.12142146404520328)\n\n\tFor 17_09_2019:\n\t\tAfternoon, Evening: 7,3\n\t\tAfternoon, Evening:(-0.45253200703182367, 0.6898742950500945)\n\n\tFor 20_09_2019:\n\t\tAfternoon, Evening: 5,2\n\t\tAfternoon, Evening:(2.4869456174285443, 0.0677054479716569)\n\n\tFor 21_09_2019:\n\t\tAfternoon, Morning: 6,3\n\t\tAfternoon, Morning:(0.9093388398040313, 0.394796667963906)\n\n\tFor 23_09_2019:\n\t\tAfternoon, Morning: 5,3\n\t\tAfternoon, Morning:(0.9999999999999994, 0.37390096630005903)\n\n"
     ]
    }
   ],
   "source": [
    "for zone in joined_dfs.keys():\n",
    "    print(f\"For {zone}: \")\n",
    "    grouped = joined_dfs[zone].groupby([\"Date\", \"Timezone\"])\n",
    "    for date in dates:\n",
    "        print(f\"\\tFor {date}:\")\n",
    "        welch_test_pair = []\n",
    "        for pair in grouped.groups.keys():\n",
    "            if date in pair:\n",
    "                welch_test_pair.append(pair)\n",
    "                if len(welch_test_pair) == 2:\n",
    "                    break\n",
    "        if not len(welch_test_pair) < 2:\n",
    "            pair_1, pair_2 = welch_test_pair\n",
    "            array_1 = list(grouped.get_group(pair_1)['score'])\n",
    "            array_2 = list(grouped.get_group(pair_2)['score'])\n",
    "            \n",
    "            print(f\"\\t\\t{pair_1[1]}, {pair_2[1]}: {len(array_1)},{len(array_2)}\")\n",
    "            print(f\"\\t\\t{pair_1[1]}, {pair_2[1]}:\"\\\n",
    "                +f\"{welch_t_test(array_1, array_2)}\")\n",
    "        else:\n",
    "            print(f\"\\t\\tOnly {len(welch_test_pair)} timezone available:\\t{welch_test_pair}.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Evening:\n\n\tFor 14_09_2019:\n\t\tNothing found!\n\tFor 15_09_2019:\n\t\tNothing found!\n\tFor 16_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 2,2\n\t\t\t(1.0, 0.49999999999999956)\n\tFor 17_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 2,3\n\t\t\t(1.5215349135496974, 0.24270395613536028)\n\tFor 20_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 1,2\n\t\t\t(nan, nan)\n\tFor 21_09_2019:\n\t\tFor pair: ('21_09_2019', 'Evening'), only available: junct_mall\n\tFor 23_09_2019:\n\t\tFor pair: ('23_09_2019', 'Evening'), only available: junct_mall\n\nFor Afternoon:\n\n\tFor 14_09_2019:\n\t\tFor pair: ('14_09_2019', 'Afternoon'), only available: junct_mall\n\tFor 15_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 5,4\n\t\t\t(1.7179113807746669, 0.13523205557263326)\n\tFor 16_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 7,8\n\t\t\t(2.6856187287007396, 0.01871571676774183)\n\tFor 17_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 3,7\n\t\t\t(0.981421517218087, 0.4050183387297711)\n\tFor 20_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 6,5\n\t\t\t(0.31311869559901456, 0.7615503986350938)\n\tFor 21_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 4,6\n\t\t\t(4.2871958271504615, 0.007809862905955828)\n\tFor 23_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 4,5\n\t\t\t(2.611672908206734, 0.0681498143863581)\n\nFor Morning:\n\n\tFor 14_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 3,2\n\t\t\t(0.2773500981126145, 0.8087684441414504)\n\tFor 15_09_2019:\n\t\tNothing found!\n\tFor 16_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 3,1\n\t\t\t(nan, nan)\n\tFor 17_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 4,3\n\t\t\t(2.5298221281347035, 0.07085622471351681)\n\tFor 20_09_2019:\n\t\tNothing found!\n\tFor 21_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 3,3\n\t\t\t(7.088306814618018, 0.0020915765975423055)\n\tFor 23_09_2019:\n\t\tjunct_mall, prantika_bus_stand: 2,3\n\t\t\t(inf, 0.0)\n\n"
     ]
    }
   ],
   "source": [
    "a, b = joined_dfs.keys()\n",
    "a_group = joined_dfs[a].groupby([\"Date\", \"Timezone\"])\n",
    "b_group = joined_dfs[b].groupby([\"Date\", \"Timezone\"])\n",
    "for timezone in set(joined_dfs[zone]['Timezone']):\n",
    "    print(f\"For {timezone}:\\n\")\n",
    "    for date in dates:\n",
    "        print(f\"\\tFor {date}:\")\n",
    "        pair = (date, timezone)\n",
    "        a_exists = pair in a_group.groups.keys()\n",
    "        b_exists = pair in b_group.groups.keys()\n",
    "        if(a_exists or b_exists):\n",
    "            if(a_exists and b_exists):\n",
    "                a_array = list(a_group.get_group(pair)['score'])\n",
    "                b_array = list(b_group.get_group(pair)['score'])\n",
    "                print(f\"\\t\\t{a}, {b}: {len(a_array)},{len(b_array)}\")\n",
    "                print(f\"\\t\\t\\t{welch_t_test(a_array, b_array)}\")\n",
    "            else:\n",
    "                print(f\"\\t\\tFor pair: {pair}, only available: \" + a if a_exists else b)\n",
    "        else:\n",
    "            print(\"\\t\\tNothing found!\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob\r\n",
    "import datetime\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from library.preprocessing import distance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "all_folders=glob.glob(\"./Trails/*/*/\")\r\n",
    "\r\n",
    "test_dates=['2019-06-28','2019-06-30','2019-07-01','2019-07-02','2019-07-03','2019-07-04','2019-07-05']\r\n",
    "formatted_test_dates=['-'.join(d.split(\"-\")[::-1]) for d in test_dates] #reversing order\r\n",
    "\r\n",
    "get_date=lambda fname:fname.split(\"\\\\\")[-2].split(\"_\")[0]\r\n",
    "get_format_date=lambda fname: '-'.join(get_date(fname).split(\"-\")[::-1])\r\n",
    "\r\n",
    "#test folders\r\n",
    "test_file_pairs=\\\r\n",
    "[(f+\"GPS.csv\",\r\n",
    " f+\"mu_serv_{}.csv\".format(get_format_date(f))) for f in all_folders if get_date(f) in formatted_test_dates]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Prev Egde speed (mean) in meter/sec"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_edge_speeds(df_gps,df_mu):\r\n",
    "    gps=df_gps.copy()\r\n",
    "    mu=df_mu.copy()\r\n",
    "    \r\n",
    "####### logic for speed means from the beginning\r\n",
    "\r\n",
    "#     gps['ts']=gps.time.apply(lambda e: e.split()[1]) #getting timestamps\r\n",
    "\r\n",
    "#     gps=gps[gps.speed>3] #filtering low spped regions\r\n",
    "\r\n",
    "#     ser=mu['start_time'].apply(lambda e: gps[gps.ts<=e].speed.mean()) # getting edge speeds from start_time\r\n",
    "\r\n",
    "#     mu['speed_in_prev']=ser.replace(np.nan,ser.mean()) #replacing NaN with means\r\n",
    "    \r\n",
    "\r\n",
    "\r\n",
    "###### logic for only edge speed\r\n",
    "\r\n",
    "    gps['ts']=gps.time.apply(lambda e: e.split()[1]) #getting timestamps\r\n",
    "\r\n",
    "    gps=gps[gps.speed>3] #filtering low spped regions\r\n",
    "\r\n",
    "    beg_time=gps.iloc[0].time.split()[1] #stat time from gps\r\n",
    "\r\n",
    "    speed=[]\r\n",
    "    for end_time in mu['start_time'].values: #end time to next stop arrival\r\n",
    "        speed.append(gps[(beg_time<=gps.ts)&(gps.ts<=end_time)].speed.mean())\r\n",
    "        beg_time=end_time #setting beg time for next edge\r\n",
    "\r\n",
    "    ser=pd.Series(speed)\r\n",
    "\r\n",
    "    mu['speed_in_prev']=ser.replace(np.nan,ser.mean()) \r\n",
    "    \r\n",
    "    return mu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get distance from the previous Stop in meter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_distance_from_prev(df_gps,df_mu):\r\n",
    "    gps=df_gps.copy()\r\n",
    "    mu=df_mu.copy()\r\n",
    "    \r\n",
    "    start_lat,start_long=gps.iloc[0][['#lat','long']].values.tolist()\r\n",
    "    dis=[]\r\n",
    "    for (next_lat,next_long) in mu[['lat','long']].values.tolist():\r\n",
    "        dis.append(distance(start_lat,start_long,next_lat,next_long))\r\n",
    "        start_lat,start_long=next_lat,next_long\r\n",
    "\r\n",
    "\r\n",
    "    mu['distance_from_prev']=dis\r\n",
    "    \r\n",
    "    return mu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add seconds to a time string"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_time_plus_delta(TIME,DELTA):\r\n",
    "    return str((pd.to_datetime(TIME)+datetime.timedelta(seconds=DELTA)).time())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting stop times from the immediate previous"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Algo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def Algo_to_pred_reach_time_from_prev_stop(df_MU,df_GPS):\r\n",
    "    df_mu=df_MU.copy()\r\n",
    "    df_gps=df_GPS.copy()\r\n",
    "    df_mu=get_edge_speeds(df_gps,df_mu)\r\n",
    "    df_mu=get_distance_from_prev(df_gps,df_mu)\r\n",
    "    speed_dict={'Afternoon': 7.8311055934586244,'Early_Morning': 7.939567834568437,\r\n",
    "                'Evening': 7.526067233283224,'Morning': 7.979809998838039}\r\n",
    "    start_time=df_gps.iloc[0].time.split()[1] #gps start time\r\n",
    "    stay_duration=0 #starting deplay is 0\r\n",
    "\r\n",
    "    pred_time_from_n_1=[]\r\n",
    "\r\n",
    "    for (tz,next_start_time,estimated_stay_duration,speed_in_prev,distance_from_prev) in df_mu[['time_zone','start_time',\r\n",
    "                                                                                        'estimated_stay_duration',\r\n",
    "                                                                                        'speed_in_prev',\r\n",
    "                                                                                        'distance_from_prev']].values.tolist():\r\n",
    "        speed_in_prev=speed_dict[tz]#17 #forefully set speed to 17m/sec\r\n",
    "        travel_time=round(distance_from_prev/speed_in_prev) #sec\r\n",
    "        pred_time_from_n_1.append(get_time_plus_delta(start_time,round(stay_duration+travel_time)))\r\n",
    "\r\n",
    "        start_time=next_start_time #for next pred  current time is taken\r\n",
    "        stay_duration=estimated_stay_duration # for next current stay is considered\r\n",
    "\r\n",
    "    df_mu['pred_time_from_n_1']=pred_time_from_n_1 #predicted times are added from the immenint previous one\r\n",
    "\r\n",
    "    # get time diffenence between pred and real in minutes\r\n",
    "    df_mu['pred_minus_start_time(min)']=\\\r\n",
    "    df_mu[['pred_time_from_n_1','start_time']].apply(lambda e:round((pd.to_datetime(e[0]).timestamp()-pd.to_datetime(e[1]).timestamp())/60,2),axis=1)\r\n",
    "\r\n",
    "    # reformatting\r\n",
    "    df_pred_from_prev=\\\r\n",
    "    df_mu[[\r\n",
    "    'time_zone',\r\n",
    "    'start_date',\r\n",
    "    'lat', 'long',\r\n",
    "    #'speed_in_prev', \r\n",
    "    'distance_from_prev',\r\n",
    "    'Is_Bus_stop', 'Is_Turn', 'Is_Signal', 'Is_Congestion', 'Is_Adhoc',\r\n",
    "    'estimated_stay_duration',\r\n",
    "    'start_time','pred_time_from_n_1',\r\n",
    "    'pred_minus_start_time(min)']]\r\n",
    "    \r\n",
    "    return df_pred_from_prev.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running in the file Structure"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for i,(gps_file,mu_file) in enumerate(test_file_pairs):\r\n",
    "    df_microServ=pd.read_csv(mu_file)\r\n",
    "    df_trail_GPS=pd.read_csv(gps_file)\r\n",
    "    pred_time_from_prev=Algo_to_pred_reach_time_from_prev_stop(df_microServ,df_trail_GPS)\r\n",
    "    \r\n",
    "    tz=pred_time_from_prev.time_zone[0] #Time Zone    \r\n",
    "    down_or_up=gps_file.split(\"\\\\\")[1] #down / up\r\n",
    "    date='-'.join(gps_file.split(\"\\\\\")[2].split(\"_\")[0].split(\"-\")[::-1]) #date\r\n",
    "    \r\n",
    "    file_to_save_in_struct=f\"pred_time_from_prev_{i}_{date}.csv\"\r\n",
    "    file_to_save_in_folder=f\"{down_or_up}_{tz}_pred_time_from_prev_{i}_{date}.csv\"\r\n",
    "    \r\n",
    "    print(\"Saving\",i,\"trail\")\r\n",
    "    pred_time_from_prev.to_csv(gps_file.split(\"GPS\")[0]+file_to_save_in_struct,index=False)\r\n",
    "    pred_time_from_prev.to_csv(\"./report/test_files/\"+file_to_save_in_folder,index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving 0 trail\n",
      "Saving 1 trail\n",
      "Saving 2 trail\n",
      "Saving 3 trail\n",
      "Saving 4 trail\n",
      "Saving 5 trail\n",
      "Saving 6 trail\n",
      "Saving 7 trail\n",
      "Saving 8 trail\n",
      "Saving 9 trail\n",
      "Saving 10 trail\n",
      "Saving 11 trail\n",
      "Saving 12 trail\n",
      "Saving 13 trail\n",
      "Saving 14 trail\n",
      "Saving 15 trail\n",
      "Saving 16 trail\n",
      "Saving 17 trail\n",
      "Saving 18 trail\n",
      "Saving 19 trail\n",
      "Saving 20 trail\n",
      "Saving 21 trail\n",
      "Saving 22 trail\n",
      "Saving 23 trail\n",
      "Saving 24 trail\n",
      "Saving 25 trail\n",
      "Saving 26 trail\n",
      "Saving 27 trail\n",
      "Saving 28 trail\n",
      "Saving 29 trail\n",
      "Saving 30 trail\n",
      "Saving 31 trail\n",
      "Saving 32 trail\n",
      "Saving 33 trail\n",
      "Saving 34 trail\n",
      "Saving 35 trail\n",
      "Saving 36 trail\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "import os\n",
    "\n",
    "for f in glob.glob(\"./Trails/*/*/pred_time_from_prev*.csv\"):\n",
    "    os.remove(f)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "glob.glob(\"./Trails/*/*/pred_time_from_prev*.csv\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./Trails\\\\down\\\\01-07-2019\\\\pred_time_from_prev_0_2019-07-01.csv',\n",
       " './Trails\\\\down\\\\01-07-2019_DATA_17_03_44\\\\pred_time_from_prev_1_2019-07-01.csv',\n",
       " './Trails\\\\down\\\\02-07-2019\\\\pred_time_from_prev_2_2019-07-02.csv',\n",
       " './Trails\\\\down\\\\02-07-2019_DATA_09_52_39\\\\pred_time_from_prev_3_2019-07-02.csv',\n",
       " './Trails\\\\down\\\\02-07-2019_DATA_11_11_23\\\\pred_time_from_prev_4_2019-07-02.csv',\n",
       " './Trails\\\\down\\\\02-07-2019_DATA_12_06_05\\\\pred_time_from_prev_5_2019-07-02.csv',\n",
       " './Trails\\\\down\\\\03-07-2019\\\\pred_time_from_prev_6_2019-07-03.csv',\n",
       " './Trails\\\\down\\\\03-07-2019_DATA_09_56_40\\\\pred_time_from_prev_7_2019-07-03.csv',\n",
       " './Trails\\\\down\\\\03-07-2019_DATA_11_52_11\\\\pred_time_from_prev_8_2019-07-03.csv',\n",
       " './Trails\\\\down\\\\03-07-2019_DATA_18_04_00\\\\pred_time_from_prev_9_2019-07-03.csv',\n",
       " './Trails\\\\down\\\\04-07-2019\\\\pred_time_from_prev_10_2019-07-04.csv',\n",
       " './Trails\\\\down\\\\04-07-2019_DATA_19_23_45\\\\pred_time_from_prev_11_2019-07-04.csv',\n",
       " './Trails\\\\down\\\\05-07-2019\\\\pred_time_from_prev_12_2019-07-05.csv',\n",
       " './Trails\\\\down\\\\05-07-2019_DATA_09_21_15\\\\pred_time_from_prev_13_2019-07-05.csv',\n",
       " './Trails\\\\down\\\\05-07-2019_DATA_10_56_28\\\\pred_time_from_prev_14_2019-07-05.csv',\n",
       " './Trails\\\\down\\\\05-07-2019_DATA_11_49_44\\\\pred_time_from_prev_15_2019-07-05.csv',\n",
       " './Trails\\\\down\\\\05-07-2019_DATA_17_01_55\\\\pred_time_from_prev_16_2019-07-05.csv',\n",
       " './Trails\\\\down\\\\05-07-2019_DATA_18_56_42\\\\pred_time_from_prev_17_2019-07-05.csv',\n",
       " './Trails\\\\down\\\\30-06-2019\\\\pred_time_from_prev_18_2019-06-30.csv',\n",
       " './Trails\\\\up\\\\01-07-2019\\\\pred_time_from_prev_19_2019-07-01.csv',\n",
       " './Trails\\\\up\\\\01-07-2019_DATA_15_59_01\\\\pred_time_from_prev_20_2019-07-01.csv',\n",
       " './Trails\\\\up\\\\02-07-2019\\\\pred_time_from_prev_21_2019-07-02.csv',\n",
       " './Trails\\\\up\\\\02-07-2019_DATA_08_59_55\\\\pred_time_from_prev_22_2019-07-02.csv',\n",
       " './Trails\\\\up\\\\02-07-2019_DATA_10_58_35\\\\pred_time_from_prev_23_2019-07-02.csv',\n",
       " './Trails\\\\up\\\\03-07-2019\\\\pred_time_from_prev_24_2019-07-03.csv',\n",
       " './Trails\\\\up\\\\03-07-2019_DATA_08_46_57\\\\pred_time_from_prev_25_2019-07-03.csv',\n",
       " './Trails\\\\up\\\\03-07-2019_DATA_10_58_15\\\\pred_time_from_prev_26_2019-07-03.csv',\n",
       " './Trails\\\\up\\\\03-07-2019_DATA_17_00_17\\\\pred_time_from_prev_27_2019-07-03.csv',\n",
       " './Trails\\\\up\\\\04-07-2019\\\\pred_time_from_prev_28_2019-07-04.csv',\n",
       " './Trails\\\\up\\\\04-07-2019_DATA_18_39_02\\\\pred_time_from_prev_29_2019-07-04.csv',\n",
       " './Trails\\\\up\\\\05-07-2019\\\\pred_time_from_prev_30_2019-07-05.csv',\n",
       " './Trails\\\\up\\\\05-07-2019_DATA_08_28_46\\\\pred_time_from_prev_31_2019-07-05.csv',\n",
       " './Trails\\\\up\\\\05-07-2019_DATA_10_09_30\\\\pred_time_from_prev_32_2019-07-05.csv',\n",
       " './Trails\\\\up\\\\05-07-2019_DATA_10_46_37\\\\pred_time_from_prev_33_2019-07-05.csv',\n",
       " './Trails\\\\up\\\\05-07-2019_DATA_16_16_42\\\\pred_time_from_prev_34_2019-07-05.csv',\n",
       " './Trails\\\\up\\\\05-07-2019_DATA_18_03_49\\\\pred_time_from_prev_35_2019-07-05.csv',\n",
       " './Trails\\\\up\\\\28-06-2019\\\\pred_time_from_prev_36_2019-06-28.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#NICE"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "b496de04c6665edfa1cca11f385086828f468dbd980bacdf8bad1da56efd0634"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
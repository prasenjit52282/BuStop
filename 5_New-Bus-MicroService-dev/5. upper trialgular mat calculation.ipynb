{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import geodesic\n",
    "from library.preprocessing import distance\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping for all test CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders=glob.glob(\"./Trails/*/*/\")\n",
    "\n",
    "test_dates=['2019-06-28','2019-06-30','2019-07-01','2019-07-02','2019-07-03','2019-07-04','2019-07-05']\n",
    "formatted_test_dates=['-'.join(d.split(\"-\")[::-1]) for d in test_dates] #reversing order\n",
    "\n",
    "get_date=lambda fname:fname.split(\"\\\\\")[-2].split(\"_\")[0]\n",
    "get_format_date=lambda fname: '-'.join(get_date(fname).split(\"-\")[::-1])\n",
    "\n",
    "\n",
    "test_pred_files=[]\n",
    "for date in test_dates:\n",
    "    test_pred_files.extend(glob.glob(\"./Trails/*/*/pred_time_from_prev*{}.csv\".format(date)))\n",
    "\n",
    "test_gps_files=[]\n",
    "for pred_file in test_pred_files:\n",
    "    test_gps_files.append(pred_file.split(\"\\\\p\")[0]+\"\\\\GPS.csv\")\n",
    "    \n",
    "test_mu_files=[]\n",
    "for pred_file in test_pred_files:\n",
    "    test_mu_files.append(glob.glob(pred_file.split(\"\\\\p\")[0]+\"\\\\mu_serv*.csv\")[0])\n",
    "\n",
    "test_file_pairs=list(zip(test_gps_files,test_pred_files,test_mu_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_necessary_stop_info(file_pair):\n",
    "    trail_type=\"up\" if \"up\" in file_pair[1] else \"down\"\n",
    "    df_pred=pd.read_csv(file_pair[1])\n",
    "    df_mu=pd.read_csv(file_pair[2])\n",
    "    df_mu[\"ETA\"]=df_pred.predicted_start_time\n",
    "    df_mu[\"Err\"]=df_pred.error_in_min\n",
    "    df_mu[\"trail\"]=trail_type\n",
    "    df_mu['speed']=df_pred.speed\n",
    "    cols=['trail','lat', 'long','speed','start_time','ETA','Err','stay_duration',\n",
    "      'estimated_stay_duration','Is_Bus_stop','Is_Turn','Is_Signal','Is_Congestion','Is_Adhoc']\n",
    "    return df_mu[cols].copy()\n",
    "\n",
    "def filter_out_bs(lat,long,df_stop):\n",
    "    for d in df_stop.values:\n",
    "        dic=dict(zip(df_stop.columns,d))\n",
    "        if distance(lat,long,dic[\"lat\"],dic[\"long\"])<30:\n",
    "            return(dic)\n",
    "    return(dict(zip(df_stop.columns,[np.nan]*df_stop.shape[1])))\n",
    "\n",
    "\n",
    "def geodistance(pointA, pointB):\n",
    "    return geodesic(pointA, pointB).meters\n",
    "\n",
    "def get_Sec_from_datetime(dt):\n",
    "    timeStamp=pd.to_datetime(dt,format=\"%m/%d/%Y %H:%M:%S\")\n",
    "    return timeStamp.timestamp()\n",
    "\n",
    "def get_time_plus_delta(TIME,DELTA):\n",
    "    return str((pd.to_datetime(TIME)+datetime.timedelta(seconds=DELTA)).time())\n",
    "\n",
    "def process_GPS(f_name):\n",
    "    df=pd.read_csv(f_name)\n",
    "    start_lat,start_long,start_time=df[['#lat','long','time']].iloc[0]\n",
    "\n",
    "    next_hop_distance=[]\n",
    "    time_elapsed=[]\n",
    "    for next_lat,next_long,next_time in df[['#lat','long','time']].values:\n",
    "        next_hop_distance.append(geodistance((start_lat,start_long),(next_lat,next_long)))\n",
    "        time_elapsed.append(get_Sec_from_datetime(next_time)-get_Sec_from_datetime(start_time)+1e-9)\n",
    "        start_lat,start_long,start_time=next_lat,next_long,next_time\n",
    "\n",
    "    #next_hop_distance\n",
    "    #time_elapsed\n",
    "    df['next_hop_distance']=next_hop_distance\n",
    "    df['time_elapsed']=time_elapsed\n",
    "    df['start_time']=df.time.apply(lambda e:e.split(\" \")[1])\n",
    "    df['lat']=df['#lat']\n",
    "    return df[['start_time','lat','long','next_hop_distance','time_elapsed']].copy()\n",
    "\n",
    "def time_zone_cal(s):\n",
    "    hour=int(s.split(':')[0])\n",
    "    if 6<hour<=9:\n",
    "        time_zone='Early_Morning'\n",
    "    elif 9<hour<=12:\n",
    "        time_zone='Morning'\n",
    "    elif 12<hour<=17:\n",
    "        time_zone='Afternoon'\n",
    "    elif 17<hour<=23:\n",
    "        time_zone='Evening'\n",
    "    return time_zone\n",
    "\n",
    "#Saving stay_duration_dict\n",
    "with open('./logs/stay_duration.pickle', 'rb') as handle:\n",
    "    stay_dic=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main code\n",
    "def get_BusStops(pair):\n",
    "    df_stop=read_necessary_stop_info(pair)\n",
    "\n",
    "    trail=df_stop.trail[0]\n",
    "    if trail=='down':\n",
    "        df_bs=pd.read_csv(\"./Labels/down/Bus_stop_down.csv\",header=None)\n",
    "    elif trail=='up':\n",
    "        df_bs=pd.read_csv(\"./Labels/up/Bus_stop_up.csv\",header=None)\n",
    "    df_bs.columns=['b_lat','b_long','BS']\n",
    "\n",
    "    BusStops=\\\n",
    "    pd.concat([df_bs,\n",
    "               pd.DataFrame(df_bs[['b_lat','b_long']].apply(lambda e: filter_out_bs(e[0],e[1],df_stop),axis=1).values.tolist())],\n",
    "             axis=1).drop(columns=['trail','lat','long','Is_Bus_stop',\n",
    "                                  'Is_Turn','Is_Signal','Is_Congestion','Is_Adhoc'])\n",
    "    BusStops.stay_duration.replace(np.nan, 0,inplace=True)\n",
    "    BusStops.start_time.replace(np.nan,\"--\",inplace=True)\n",
    "\n",
    "    gps_df=process_GPS(pair[0])\n",
    "\n",
    "    #Recalculating.........\n",
    "    cal_speed_on_past_min=20\n",
    "    total_stay=0\n",
    "    START_TIME=[];SPEED=[];DIS=[];ESTIMATED_STAY=[]\n",
    "    prev_dis=0\n",
    "    for index,(start_lat,start_long,start_stay_dur) in enumerate(BusStops[['b_lat','b_long','stay_duration']].values):\n",
    "        dis=0\n",
    "        for stime,lat,long,d in gps_df[['start_time','lat','long','next_hop_distance']].values:\n",
    "            dis+=d\n",
    "            if geodistance((lat,long),(start_lat,start_long))<=30:\n",
    "                total_stay+=start_stay_dur\n",
    "                prev_time=get_time_plus_delta(stime,(-cal_speed_on_past_min*60)) #past 20 min speed is calculated\n",
    "                df_past_patch=gps_df[(gps_df.start_time<=stime)&(gps_df.start_time>=prev_time)].copy()\n",
    "                speed=df_past_patch.next_hop_distance.sum()/(df_past_patch.time_elapsed.sum()-total_stay)\n",
    "                if index==0:\n",
    "                    speed={'Afternoon': 3.208857802457898,\n",
    "                    'Early_Morning': 2.4823871880135058,\n",
    "                    'Evening': 1.9810927189917138,\n",
    "                    'Morning': 3.0719420700235105}[time_zone_cal(stime)]\n",
    "                START_TIME.append(stime)\n",
    "                SPEED.append(speed)\n",
    "                ESTIMATED_STAY.append(stay_dic['Is_Bus_stop'][time_zone_cal(stime)])\n",
    "                DIS.append(dis-prev_dis)\n",
    "                prev_dis=dis\n",
    "                break\n",
    "\n",
    "    #Replacing NaN values\n",
    "\n",
    "    BusStops['speed']=\\\n",
    "    BusStops.reset_index()[['index','speed']].apply(lambda e:SPEED[int(e[0])] if np.isnan(e[1]) else e[1],axis=1)\n",
    "\n",
    "    BusStops['start_time']=\\\n",
    "    BusStops.reset_index()[['index','start_time']].apply(lambda e:START_TIME[int(e[0])] if e[1]=='--' else e[1],axis=1)\n",
    "\n",
    "    BusStops['estimated_stay_duration']=ESTIMATED_STAY\n",
    "\n",
    "    BusStops['distance_from_prev']=DIS\n",
    "    return BusStops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_triangular_matrix_df(dataframe):\n",
    "    df=dataframe.copy()\n",
    "    error_matrix=[]\n",
    "    ETA_matrix=[]\n",
    "    for start_bs in range(1,df.shape[0]+1): #1st bus stop\n",
    "\n",
    "        start_time=df.iloc[start_bs-1].start_time\n",
    "        stay_duration=df.iloc[start_bs-1].estimated_stay_duration\n",
    "\n",
    "        error=[np.nan]*start_bs\n",
    "        eta=['--']*start_bs\n",
    "\n",
    "        for speed,next_start_time,estimated_stay_duration,prevDist in df[['speed',\n",
    "                                                                    'start_time',\n",
    "                                                                    'estimated_stay_duration',\n",
    "                                                                    'distance_from_prev']].iloc[start_bs:].values.tolist():\n",
    "\n",
    "            travel_speed=speed\n",
    "            travel_time=round(prevDist/travel_speed) #sec\n",
    "            estimated_reach_time=get_time_plus_delta(start_time,round(stay_duration+travel_time)) #timestamp\n",
    "\n",
    "            c_error=round((pd.to_datetime(estimated_reach_time).timestamp()-pd.to_datetime(next_start_time).timestamp())/60,2)\n",
    "            error.append(c_error)\n",
    "            eta.append(estimated_reach_time)\n",
    "\n",
    "            start_time=estimated_reach_time #start time fr next hope is estimated\n",
    "            stay_duration=estimated_stay_duration # estimated stay will be added to compute the next\n",
    "\n",
    "        error_matrix.append(error)\n",
    "        ETA_matrix.append(eta)\n",
    "        \n",
    "        BS_names=dataframe[['BS','stay_duration']].apply(lambda e:e[0]+\"(s)\" if e[1]==0 else e[0],axis=1)\n",
    "\n",
    "    return (pd.DataFrame(ETA_matrix,index=BS_names,columns=BS_names),\n",
    "            pd.DataFrame(error_matrix,index=BS_names,columns=BS_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ETA_and_ERROR(pair):\n",
    "    BusStops=get_BusStops(pair)\n",
    "    ETA,error=get_upper_triangular_matrix_df(BusStops)\n",
    "    return ETA,error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,7))\n",
    "sns.heatmap(error,annot=True)\n",
    "plt.show()\n",
    "\n",
    "BS_ETA_DICT=dict(zip(ETA.columns,ETA.T.values.tolist()))\n",
    "BS_ETA_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved for  up_28-06-2019_0\n",
      "Saved for  down_30-06-2019_1\n",
      "Saved for  down_01-07-2019_2\n",
      "Saved for  down_01-07-2019_DATA_17_03_44_3\n",
      "Saved for  up_01-07-2019_4\n",
      "Saved for  up_01-07-2019_DATA_15_59_01_5\n",
      "Error in processing file down_02-07-2019_6\n",
      "Saved for  down_02-07-2019_DATA_09_52_39_7\n",
      "Error in processing file down_02-07-2019_DATA_11_11_23_8\n",
      "Saved for  down_02-07-2019_DATA_12_06_05_9\n",
      "Saved for  up_02-07-2019_10\n",
      "Saved for  up_02-07-2019_DATA_08_59_55_11\n",
      "Saved for  up_02-07-2019_DATA_10_58_35_12\n",
      "Error in processing file down_03-07-2019_13\n",
      "Error in processing file down_03-07-2019_DATA_09_56_40_14\n",
      "Error in processing file down_03-07-2019_DATA_11_52_11_15\n",
      "Error in processing file down_03-07-2019_DATA_18_04_00_16\n",
      "Saved for  up_03-07-2019_17\n",
      "Error in processing file up_03-07-2019_DATA_08_46_57_18\n",
      "Error in processing file up_03-07-2019_DATA_10_58_15_19\n",
      "Saved for  up_03-07-2019_DATA_17_00_17_20\n",
      "Error in processing file down_04-07-2019_21\n",
      "Saved for  down_04-07-2019_DATA_19_23_45_22\n",
      "Saved for  up_04-07-2019_23\n",
      "Saved for  up_04-07-2019_DATA_18_39_02_24\n",
      "Error in processing file down_05-07-2019_25\n",
      "Saved for  down_05-07-2019_DATA_09_21_15_26\n",
      "Error in processing file down_05-07-2019_DATA_10_56_28_27\n",
      "Saved for  down_05-07-2019_DATA_11_49_44_28\n",
      "Error in processing file down_05-07-2019_DATA_17_01_55_29\n",
      "Saved for  down_05-07-2019_DATA_18_56_42_30\n",
      "Saved for  up_05-07-2019_31\n",
      "Saved for  up_05-07-2019_DATA_08_28_46_32\n",
      "Saved for  up_05-07-2019_DATA_10_09_30_33\n",
      "Saved for  up_05-07-2019_DATA_10_46_37_34\n",
      "Saved for  up_05-07-2019_DATA_16_16_42_35\n",
      "Saved for  up_05-07-2019_DATA_18_03_49_36\n"
     ]
    }
   ],
   "source": [
    "for i,pair in enumerate(test_file_pairs):\n",
    "    base_name=pair[0].split(\"\\\\\")[1]+\"_\"+pair[0].split(\"\\\\\")[2]+f\"_{i}\"\n",
    "    if os.path.exists(f\"./report/BS_Matrices/ERR/{base_name}_ETA.csv\")==True:\n",
    "        print(\"Already processed\",base_name)\n",
    "        continue\n",
    "    try:\n",
    "        ETA,error=get_ETA_and_ERROR(pair)\n",
    "        ETA.to_csv(f\"./report/BS_Matrices/ERR/{base_name}_ETA.csv\")\n",
    "        error.to_csv(f\"./report/BS_Matrices/ETA/{base_name}_ERR.csv\")\n",
    "        print(\"Saved for \",base_name)\n",
    "    except:\n",
    "        print(\"Error in processing file\", base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NICE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b496de04c6665edfa1cca11f385086828f468dbd980bacdf8bad1da56efd0634"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from library.preprocessing import new_Processing_before_journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders=glob.glob(\"./Trails/*/*/\")\n",
    "\n",
    "test_dates=['2019-06-28','2019-06-30','2019-07-01','2019-07-02','2019-07-03','2019-07-04','2019-07-05']\n",
    "formatted_test_dates=['-'.join(d.split(\"-\")[::-1]) for d in test_dates] #reversing order\n",
    "\n",
    "#train folders\n",
    "train_folders=[f for f in all_folders if f.split(\"\\\\\")[-2].split(\"_\")[0] not in formatted_test_dates]\n",
    "\n",
    "#test folders\n",
    "test_folders=[f for f in all_folders if f.split(\"\\\\\")[-2].split(\"_\")[0] in formatted_test_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./logs/rfs.pickle', 'rb') as handle:\n",
    "    rfs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature # binding\n",
    "F=\\\n",
    "    {1:'stay_duration', #f1\n",
    "     2:'mfcc0',3:'mfcc1',4:'mfcc2',5:'mfcc3',6:'mfcc4', #f2,f3,f4,f5,f6\n",
    "     7:'wifi_count', 8:'edge_wifi_count', #f7,f8\n",
    "     9:'RSI', #f9\n",
    "     10:'human_made', 11:'natural_land',12:'road_exist_percent',13:'highly_populated_poi_exist'#f10,f11,f12,f13\n",
    "    }\n",
    "\n",
    "selected_feat=\\\n",
    "    {\n",
    "        'Is_Bus_stop':[F[e] for e in [10,12,11,1,8]],\n",
    "        'Is_Turn':[F[e] for e in [10,12,11,1,8,9]],\n",
    "        'Is_Signal':[F[e] for e in [12,11,10,8,9]],\n",
    "        'Is_Congestion':[F[e] for e in [2,11,10,9,12,8,6,1]],\n",
    "        'Is_Adhoc':[F[e] for e in [10,11,1,12,2]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Training DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_training_data(folder):\n",
    "    we_need=['time_zone','start_date','start_time','lat','long','stay_duration']+list(rfs.keys())\n",
    "    return new_Processing_before_journal(folder+\"ALL_DATA.csv\")[we_need]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in train_folders:\n",
    "    f_df=process_training_data(folder)\n",
    "    formatted_date='-'.join(folder.split(\"\\\\\")[-2].split(\"_\")[0].split(\"-\")[::-1])\n",
    "    f_df.start_date=formatted_date\n",
    "    f_df.to_csv(folder+f\"mu_serv_{formatted_date}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Testing DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_testing_data(folder):\n",
    "    we_need=['time_zone','start_date','start_time','lat','long','stay_duration']+list(rfs.keys())\n",
    "    df= new_Processing_before_journal(folder+\"ALL_DATA.csv\")\n",
    "    for poi_column in rfs.keys():\n",
    "        feature_names=selected_feat[poi_column]\n",
    "        test_data = df[feature_names].values\n",
    "        pred=rfs[poi_column].predict(test_data)\n",
    "        df[poi_column]=pred\n",
    "    return df[we_need]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in test_folders:\n",
    "    f_df=process_testing_data(folder)\n",
    "    formatted_date='-'.join(folder.split(\"\\\\\")[-2].split(\"_\")[0].split(\"-\")[::-1])\n",
    "    f_df.start_date=formatted_date\n",
    "    f_df.to_csv(folder+f\"mu_serv_{formatted_date}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
